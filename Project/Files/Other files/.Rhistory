## predictive Analytics -- Data cleaning and PCA with R -- @Anasse Bari
## modified by Renke Cai, Xueying(Sharon) Liang, Shengnan(Nancy) Li
## 10/4/2016
############ prepare the external libraries #############
# install packages - first time only
install.packages("e1071")
install.packages("caret")
install.packages("FSelector")
# libraries
library(e1071)
library(caret)
library(FSelector)
############# prepare the data ################
# Pls add the headers to your orginal data file
# Pls change the path to your actual path!
path <- "C:/Users/caire/Documents/Data/hepatitis.csv"
hepatitis <- read.csv(path, na.strings="?")  # recognize questions marks as NA
# make it a label
hepatitis$Class <- as.factor(hepatitis$Class)
# take a look at first several lines of data
head(hepatitis)
#split the data into training and testing data randomly at a specified percentage
training_pct <- 0.7
training_indices <- createDataPartition(hepatitis$Class, p = training_pct)[[1]]
training_hepatitis <- hepatitis[training_indices, ]
test_hepatitis <- hepatitis[-training_indices, ]
# check that data are split accordingly
dim(training_hepatitis)
dim(test_hepatitis)
############# handle missing values #######################
# function to fill in missing values
fill_in_values <- function(data, strategy){
numeric_cols <- sapply(data[1,], is.numeric)
data[, numeric_cols] <- apply(data[ , numeric_cols], 2, function(x){
is_na <- is.na(x)
# use valid values to replace missing ones with a given strategy
x[is_na] <- strategy(x[!is_na])
x
})
data
}
# calculate accuracy
get_accuracy <- function(predicted, golden) mean(predicted == golden)
# function to cross validate a model
cv_perf <- function(train_model, get_golden, data, k=10) {
folds_indices <- createFolds(1:nrow(data),k)
accuracy <- 0
for (test_indices in folds_indices) {
training_data <- data[-test_indices, ]
test_data <- data[test_indices, ]
trained_model <- train_model(training_data)
predicted <- predict(trained_model, newdata = test_data)
golden <- get_golden(test_data)
accuracy <- accuracy + get_accuracy(predicted, golden)
}
accuracy / k
}
# test value replacement strategies
replacement_strategies <- list(max, min, mean)
names(replacement_strategies) <- c("max", "min", "mean")
# test the replacement strategy on training data only
replaced_data <- lapply(replacement_strategies, function(fn) fill_in_values(training_hepatitis, fn))
train_nb <- function(x) naiveBayes(Class ~ . , data=x)
get_golden <- function(x) x$Class
replaced_data_performance <- lapply(replaced_data, function(d) cv_perf(train_nb, get_golden, data=d, k=10))
# display the performance of the three methods
# the mean outperforms ???
replaced_data_performance
#
############# go on with using mean for the missing value replacement of entire dataset ###########
# prepare the filled data
hepatitis_filled <- fill_in_values(hepatitis, mean)
training_hepatitis_filled <- hepatitis_filled[training_indices, ]
test_hepatitis_filled <- hepatitis_filled[-training_indices, ]
#perform PCA and SVD, drop the label column
hep_pca <- prcomp(hepatitis_filled[ ,-1])
hep_projected <- cbind(hepatitis_filled[,1], as.data.frame(as.matrix(hepatitis_filled[,-1]) %*% hep_pca$rotation))
hep_svd <- svd(hepatitis_filled[,-1])
################ feature selection strategies representing as functions #############
# create a list of strategies
feature_selection_strategies <- list(cfs, chi.squared, information.gain, gain.ratio)
names(feature_selection_strategies) <- c("cfs", "x-sqr", "info-gain", "gain-ratio")
# Return the features (which is a simple formula contaning selected features) as selected by strategies
apply_feature_selection <- function(strategy, refine, base_formula, data){
feature_result <- strategy(base_formula, data)
refined <- refine(feature_result)
as.simple.formula(refined, all.vars(base_formula)[1])
}
# specify a cut_off value
cut_off <- 5
# refinement strategies: a vactor containing 4 functions [x, cutoff.k(x,5), cutoff.k(x,5), cutoff.k(x,5)]
refinement_strategies <- c(identity, # cfs,
rep(c(function(x) cutoff.k(x,cut_off)), 3)
)
all_feature_formula <- Class ~ .
# a list of 4 formulas corresponding to each strategy/refinement
features_selected <- mapply(function(s, r) apply_feature_selection(s, r, all_feature_formula, training_hepatitis_filled),
feature_selection_strategies, refinement_strategies)
# cross-validate these features on the training dataset to select the model
train_nb_with_spec <- function(f) function(d) naiveBayes(f, d)
cv_perf_feat_selection <- lapply(features_selected, function(m) cv_perf(train_nb_with_spec(m),
get_golden, training_hepatitis_filled, k=10))
# display the performance
cv_perf_feat_selection
############# using info-gain and a cutoff of 5 to go on #####################
best_model_spec <- features_selected[["info-gain"]]
trained_model <- naiveBayes(best_model_spec, training_hepatitis_filled)
test_accuracy <- get_accuracy(predict(trained_model, newdata=test_hepatitis_filled), get_golden(test_hepatitis_filled))
print(paste("Test Accuracy", test_accuracy, spec = " "))
clearPushBack()
Practice.R
Practice.R
features_selected <- mapply(function(s, r) apply_feature_selection(s, r, all_feature_formula, training_hepatitis_filled),
s
end
cv_perf_feat_selection
delete.response()
delete
cl
clear
install.packages("caret")
library(FSelector)
############# prepare the data ################
# Pls add the headers to your orginal data file
a
pl[,6]
library("forecast")
library(ggplot2)
require("tsoutliers")
library("tseries")
library("imputeTS")
plot ( [1,1,1 ])
plot ( [1;1;1 ])
x= [1,1,1,1]
x = matrix(2,2,2)
y = x[,1]
plot y
plot (y)
pl_data=read.csv("matrixdf.csv")
pl2_data=pl_data
setwd("/Users/vipinarora/Desktop/GradSem1/Predictive\ Analytics/Project/repredictiveanalyticsproject/arima_images")
setwd("/Users/vipinarora/Desktop/GradSem1/Predictive\ Analytics/Project/repredictiveanalyticsproject")
pl_data=read.csv("matrixdf.csv")
pl2_data=pl_data
i = 2
x = pl2_data[,i]
fit1 <- auto.arima(pl2_data[,i])
#fit1 <- arima(ger$X2002..YR2002.)
fit1
y <- pl2_data[,i]
#kr <- KalmanSmooth(pl2_data[,i], fit1$model)
kr <- KalmanRun(pl2_data[,i], fit1$model)
fit1 <- auto.arima(pl2_data[,i])
fit1
library("tseries")
library("forecast")
x = pl2_data[,i]
fit1 <- auto.arima(pl2_data[,i])
y <- pl2_data[,i]
kr <- KalmanRun(pl2_data[,i], fit1$model)
id.na <- which(is.na(pl2_data[,i]))
fit1
fit1$model
fit1$model$Z
kr
#tmp <- which(fit1$model$Z == 1)
#id <- ifelse (length(tmp) == 1, tmp[1], tmp[2])
#id.na <- which(is.na(pl2_data[,i]))
#msci.filled <- pl2_data[,i]
#msci.filled[id.na] <- kr$smooth[id.na,id]
id.na <- which(is.na(pl2_data[,i]))
for (j in id.na)
y[j] <- fit1$model$Z %*% kr$states[j,]
sapply(id.na, FUN = function(x, Z, alpha) Z %*% alpha[x,],
Z = fit1$model$Z, alpha = kr$states)
y[id.na]
kr <- KalmanSmooth(pl2_data[,i], fit1$model)
t = pl2_data[,i]
for (j in id.na)
t[j] <- kr$smooth[j,]
#plot(pl2_data[,i], ylim = c(0, 1.5), xlim = c(1,37))
plot(pl2_data[,i], ylim = c(0, 1.5), xlim = c(1,37))
lines(y, col="blue")
lines(t, col="red")
i = 3
# p2006 <- pl2_data[,i][35]
x = pl2_data[,i]
fit1 <- auto.arima(pl2_data[,i])
#fit1 <- arima(ger$X2002..YR2002.)
fit1
y <- pl2_data[,i]
#kr <- KalmanSmooth(pl2_data[,i], fit1$model)
kr <- KalmanRun(pl2_data[,i], fit1$model)
#tmp <- which(fit1$model$Z == 1)
#id <- ifelse (length(tmp) == 1, tmp[1], tmp[2])
#id.na <- which(is.na(pl2_data[,i]))
#msci.filled <- pl2_data[,i]
#msci.filled[id.na] <- kr$smooth[id.na,id]
id.na <- which(is.na(pl2_data[,i]))
for (j in id.na)
y[j] <- fit1$model$Z %*% kr$states[j,]
sapply(id.na, FUN = function(x, Z, alpha) Z %*% alpha[x,],
Z = fit1$model$Z, alpha = kr$states)
y[id.na]
kr <- KalmanSmooth(pl2_data[,i], fit1$model)
t = pl2_data[,i]
for (j in id.na)
t[j] <- kr$smooth[j,]
plot(pl2_data[,i], ylim = c(0, 1.5), xlim = c(1,37))
lines(y, col="blue")
lines(t, col="red")
i = 4
x = pl2_data[,i]
fit1 <- auto.arima(pl2_data[,i])
#fit1 <- arima(ger$X2002..YR2002.)
fit1
y <- pl2_data[,i]
#kr <- KalmanSmooth(pl2_data[,i], fit1$model)
kr <- KalmanRun(pl2_data[,i], fit1$model)
#tmp <- which(fit1$model$Z == 1)
#id <- ifelse (length(tmp) == 1, tmp[1], tmp[2])
#id.na <- which(is.na(pl2_data[,i]))
#msci.filled <- pl2_data[,i]
#msci.filled[id.na] <- kr$smooth[id.na,id]
id.na <- which(is.na(pl2_data[,i]))
for (j in id.na)
y[j] <- fit1$model$Z %*% kr$states[j,]
sapply(id.na, FUN = function(x, Z, alpha) Z %*% alpha[x,],
Z = fit1$model$Z, alpha = kr$states)
y[id.na]
kr <- KalmanSmooth(pl2_data[,i], fit1$model)
t = pl2_data[,i]
for (j in id.na)
t[j] <- kr$smooth[j,]
plot(pl2_data[,i], ylim = c(0, 1.5), xlim = c(1,37))
lines(y, col="blue")
lines(t, col="red")
i = 14
x = pl2_data[,i]
fit1 <- auto.arima(pl2_data[,i])
#fit1 <- arima(ger$X2002..YR2002.)
fit1
y <- pl2_data[,i]
#kr <- KalmanSmooth(pl2_data[,i], fit1$model)
kr <- KalmanRun(pl2_data[,i], fit1$model)
#tmp <- which(fit1$model$Z == 1)
#id <- ifelse (length(tmp) == 1, tmp[1], tmp[2])
#id.na <- which(is.na(pl2_data[,i]))
#msci.filled <- pl2_data[,i]
#msci.filled[id.na] <- kr$smooth[id.na,id]
id.na <- which(is.na(pl2_data[,i]))
for (j in id.na)
y[j] <- fit1$model$Z %*% kr$states[j,]
sapply(id.na, FUN = function(x, Z, alpha) Z %*% alpha[x,],
Z = fit1$model$Z, alpha = kr$states)
y[id.na]
kr <- KalmanSmooth(pl2_data[,i], fit1$model)
t = pl2_data[,i]
for (j in id.na)
t[j] <- kr$smooth[j,]
plot(pl2_data[,i], ylim = c(0, 1.5), xlim = c(1,37))
lines(y, col="blue")
lines(t, col="red")
#adf.test(y, alternative = "stationary") #Using 5% threshold, differencing is required if p-value > 0.05.
i = 19
x = pl2_data[,i]
fit1 <- auto.arima(pl2_data[,i])
#fit1 <- arima(ger$X2002..YR2002.)
fit1
y <- pl2_data[,i]
#kr <- KalmanSmooth(pl2_data[,i], fit1$model)
kr <- KalmanRun(pl2_data[,i], fit1$model)
#tmp <- which(fit1$model$Z == 1)
#id <- ifelse (length(tmp) == 1, tmp[1], tmp[2])
#id.na <- which(is.na(pl2_data[,i]))
#msci.filled <- pl2_data[,i]
#msci.filled[id.na] <- kr$smooth[id.na,id]
id.na <- which(is.na(pl2_data[,i]))
for (j in id.na)
y[j] <- fit1$model$Z %*% kr$states[j,]
sapply(id.na, FUN = function(x, Z, alpha) Z %*% alpha[x,],
Z = fit1$model$Z, alpha = kr$states)
y[id.na]
kr <- KalmanSmooth(pl2_data[,i], fit1$model)
t = pl2_data[,i]
for (j in id.na)
t[j] <- kr$smooth[j,]
plot(pl2_data[,i], ylim = c(0, 1.5), xlim = c(1,37))
lines(y, col="blue")
lines(t, col="red")
i = 62
x = pl2_data[,i]
fit1 <- auto.arima(pl2_data[,i])
#fit1 <- arima(ger$X2002..YR2002.)
fit1
y <- pl2_data[,i]
#kr <- KalmanSmooth(pl2_data[,i], fit1$model)
kr <- KalmanRun(pl2_data[,i], fit1$model)
#tmp <- which(fit1$model$Z == 1)
#id <- ifelse (length(tmp) == 1, tmp[1], tmp[2])
#id.na <- which(is.na(pl2_data[,i]))
#msci.filled <- pl2_data[,i]
#msci.filled[id.na] <- kr$smooth[id.na,id]
id.na <- which(is.na(pl2_data[,i]))
for (j in id.na)
y[j] <- fit1$model$Z %*% kr$states[j,]
sapply(id.na, FUN = function(x, Z, alpha) Z %*% alpha[x,],
Z = fit1$model$Z, alpha = kr$states)
y[id.na]
kr <- KalmanSmooth(pl2_data[,i], fit1$model)
t = pl2_data[,i]
for (j in id.na)
t[j] <- kr$smooth[j,]
plot(pl2_data[,i], ylim = c(0, 1.5), xlim = c(1,37))
lines(y, col="blue")
lines(t, col="red")
